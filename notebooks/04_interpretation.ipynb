{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBB Permeability Prediction: Model Interpretation and SAR Analysis\n",
    "\n",
    "This notebook focuses on understanding model predictions and extracting chemical insights for BBB permeability.\n",
    "\n",
    "## Objectives\n",
    "1. Load trained models and analyze feature importance\n",
    "2. Perform SHAP analysis for individual prediction explanations\n",
    "3. Visualize chemical space using dimensionality reduction\n",
    "4. Analyze structure-activity relationships (SAR)\n",
    "5. Identify key molecular substructures for BBB permeability\n",
    "6. Generate actionable insights for drug design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning and interpretability\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Chemistry libraries\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, rdMolDescriptors, Fragments\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import rdFMCS\n",
    "\n",
    "# Import project modules\n",
    "from data_handler import DataHandler\n",
    "from interpretability import InterpretabilityEngine\n",
    "from visualization import VisualizationSuite\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize SHAP\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data with descriptors\n",
    "data_with_descriptors = pd.read_csv('../data/BBBP_with_descriptors.csv')\n",
    "\n",
    "print(f\"Loaded data with descriptors: {data_with_descriptors.shape}\")\n",
    "print(f\"Class distribution: {data_with_descriptors['p_np'].value_counts().to_dict()}\")\n",
    "\n",
    "# Load trained models\n",
    "models_dir = '../results/models/'\n",
    "available_models = {}\n",
    "\n",
    "model_files = {\n",
    "    'Random Forest': 'best_model_random_forest.pkl',\n",
    "    'XGBoost': 'best_model_xgboost.pkl',\n",
    "    'SVM': 'best_model_svm.pkl',\n",
    "    'Logistic Regression': 'best_model_logistic_regression.pkl',\n",
    "    'Neural Network': 'best_model_neural_network.pkl'\n",
    "}\n",
    "\n",
    "for model_name, filename in model_files.items():\n",
    "    model_path = models_dir + filename\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            model = joblib.load(model_path)\n",
    "            available_models[model_name] = model\n",
    "            print(f\"✓ Loaded {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load {model_name}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"✗ Model file not found: {filename}\")\n",
    "\n",
    "# Load feature scaler\n",
    "scaler_path = models_dir + 'feature_scaler.pkl'\n",
    "if os.path.exists(scaler_path):\n",
    "    feature_scaler = joblib.load(scaler_path)\n",
    "    print(f\"✓ Loaded feature scaler\")\n",
    "else:\n",
    "    print(f\"✗ Feature scaler not found\")\n",
    "    feature_scaler = None\n",
    "\n",
    "# Load selected features\n",
    "features_path = models_dir + 'selected_features.txt'\n",
    "if os.path.exists(features_path):\n",
    "    with open(features_path, 'r') as f:\n",
    "        selected_features = [line.strip() for line in f.readlines()]\n",
    "    print(f\"✓ Loaded {len(selected_features)} selected features\")\n",
    "else:\n",
    "    print(f\"✗ Selected features file not found\")\n",
    "    selected_features = None\n",
    "\n",
    "print(f\"\\nAvailable models: {list(available_models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for interpretation\n",
    "exclude_columns = ['num', 'name', 'smiles', 'p_np', 'mol_object', 'smiles_length']\n",
    "descriptor_columns = [col for col in data_with_descriptors.columns \n",
    "                     if col not in exclude_columns and \n",
    "                     data_with_descriptors[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "X = data_with_descriptors[descriptor_columns].fillna(0)\n",
    "y = data_with_descriptors['p_np']\n",
    "\n",
    "# Apply feature selection and scaling if available\n",
    "if selected_features is not None:\n",
    "    X_selected = X[selected_features]\n",
    "    print(f\"Applied feature selection: {X_selected.shape}\")\n",
    "else:\n",
    "    X_selected = X\n",
    "    selected_features = descriptor_columns\n",
    "\n",
    "if feature_scaler is not None:\n",
    "    X_processed = feature_scaler.transform(X_selected)\n",
    "    print(f\"Applied feature scaling: {X_processed.shape}\")\n",
    "else:\n",
    "    X_processed = StandardScaler().fit_transform(X_selected)\n",
    "    print(f\"Applied standard scaling: {X_processed.shape}\")\n",
    "\n",
    "print(f\"Final feature matrix shape: {X_processed.shape}\")\n",
    "print(f\"Number of features: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize interpretability engine\n",
    "interp_engine = InterpretabilityEngine()\n",
    "\n",
    "# Analyze feature importance for tree-based models\n",
    "feature_importance_results = {}\n",
    "\n",
    "for model_name, model in available_models.items():\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(f\"\\nAnalyzing feature importance for {model_name}:\")\n",
    "        \n",
    "        # Calculate feature importance\n",
    "        importance = pd.Series(model.feature_importances_, index=selected_features)\n",
    "        importance = importance.sort_values(ascending=False)\n",
    "        \n",
    "        feature_importance_results[model_name] = importance\n",
    "        \n",
    "        # Display top features\n",
    "        print(f\"Top 10 important features:\")\n",
    "        for i, (feature, imp) in enumerate(importance.head(10).items(), 1):\n",
    "            print(f\"{i:2d}. {feature:<25}: {imp:.4f}\")\n",
    "\n",
    "# Select best model for detailed analysis\n",
    "if 'Random Forest' in available_models:\n",
    "    best_model_name = 'Random Forest'\n",
    "elif 'XGBoost' in available_models:\n",
    "    best_model_name = 'XGBoost'\n",
    "else:\n",
    "    best_model_name = list(available_models.keys())[0]\n",
    "\n",
    "best_model = available_models[best_model_name]\n",
    "print(f\"\\nUsing {best_model_name} for detailed interpretability analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "if feature_importance_results:\n",
    "    n_models = len(feature_importance_results)\n",
    "    fig, axes = plt.subplots(1, min(n_models, 2), figsize=(15, 8))\n",
    "    \n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    elif n_models > 2:\n",
    "        # Show only top 2 models\n",
    "        model_names = list(feature_importance_results.keys())[:2]\n",
    "        feature_importance_results = {k: feature_importance_results[k] for k in model_names}\n",
    "    \n",
    "    for i, (model_name, importance) in enumerate(feature_importance_results.items()):\n",
    "        ax = axes[i] if n_models > 1 else axes[0]\n",
    "        \n",
    "        # Plot top 15 features\n",
    "        top_features = importance.head(15)\n",
    "        \n",
    "        bars = ax.barh(range(len(top_features)), top_features.values, \n",
    "                      color='steelblue', alpha=0.8)\n",
    "        ax.set_yticks(range(len(top_features)))\n",
    "        ax.set_yticklabels(top_features.index, fontsize=10)\n",
    "        ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "        ax.set_title(f'{model_name} - Feature Importance', fontsize=14, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, axis='x', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for j, (bar, value) in enumerate(zip(bars, top_features.values)):\n",
    "            ax.text(value + max(top_features.values) * 0.01, j, f'{value:.3f}', \n",
    "                   va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP Analysis for Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SHAP analysis\n",
    "print(f\"Performing SHAP analysis for {best_model_name}...\")\n",
    "\n",
    "try:\n",
    "    # Sample data for SHAP analysis (to reduce computation time)\n",
    "    sample_size = min(500, len(X_processed))\n",
    "    sample_indices = np.random.choice(len(X_processed), sample_size, replace=False)\n",
    "    X_sample = X_processed[sample_indices]\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1]  # For binary classification, take positive class\n",
    "    else:\n",
    "        explainer = shap.Explainer(best_model, X_sample)\n",
    "        shap_values = explainer(X_sample)\n",
    "        if hasattr(shap_values, 'values'):\n",
    "            shap_values = shap_values.values\n",
    "    \n",
    "    print(f\"✓ SHAP analysis completed\")\n",
    "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "    \n",
    "    # SHAP summary plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_sample, \n",
    "                     feature_names=selected_features, show=False, max_display=20)\n",
    "    plt.title(f'{best_model_name} - SHAP Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # SHAP waterfall plot for a sample prediction\n",
    "    sample_idx = 0\n",
    "    if hasattr(explainer, 'expected_value'):\n",
    "        expected_value = explainer.expected_value\n",
    "        if isinstance(expected_value, np.ndarray):\n",
    "            expected_value = expected_value[1] if len(expected_value) > 1 else expected_value[0]\n",
    "    else:\n",
    "        expected_value = 0.5  # Default for binary classification\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Create a simple waterfall-style plot\n",
    "    sample_shap = shap_values[sample_idx]\n",
    "    sample_features = X_sample[sample_idx]\n",
    "    \n",
    "    # Sort by absolute SHAP value\n",
    "    feature_impact = [(selected_features[i], sample_shap[i], sample_features[i]) \n",
    "                     for i in range(len(selected_features))]\n",
    "    feature_impact.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    # Plot top 15 features\n",
    "    top_impact = feature_impact[:15]\n",
    "    features = [x[0] for x in top_impact]\n",
    "    shap_vals = [x[1] for x in top_impact]\n",
    "    \n",
    "    colors = ['red' if x < 0 else 'blue' for x in shap_vals]\n",
    "    plt.barh(range(len(features)), shap_vals, color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('SHAP Value')\n",
    "    plt.title(f'SHAP Explanation - Sample Prediction')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"SHAP analysis failed: {str(e)}\")\n",
    "    print(\"Continuing with other analyses...\")\n",
    "    shap_values = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chemical Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze chemical space using PCA\n",
    "print(\"Analyzing chemical space...\")\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_processed)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"✓ Chemical space analysis completed\")\n",
    "print(f\"Explained variance (first 3 components): {explained_variance}\")\n",
    "print(f\"Cumulative variance: {explained_variance.sum():.3f}\")\n",
    "\n",
    "# 2D PCA visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                     c=y, cmap='RdYlBu_r', alpha=0.7, s=50)\n",
    "plt.colorbar(scatter, label='BBB Permeability')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "plt.title('Chemical Space Visualization: PCA of Molecular Descriptors')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', alpha=0.7, label='Non-Permeable'),\n",
    "                  Patch(facecolor='blue', alpha=0.7, label='Permeable')]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D chemical space visualization\n",
    "if X_pca.shape[1] >= 3:\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=X_pca[:, 0],\n",
    "        y=X_pca[:, 1],\n",
    "        z=X_pca[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=y,\n",
    "            colorscale='RdYlBu_r',\n",
    "            opacity=0.7,\n",
    "            colorbar=dict(title=\"BBB Permeability\")\n",
    "        ),\n",
    "        text=[f'Compound {i}' for i in range(len(y))],\n",
    "        hovertemplate='<b>%{text}</b><br>' +\n",
    "                     'PC1: %{x:.2f}<br>' +\n",
    "                     'PC2: %{y:.2f}<br>' +\n",
    "                     'PC3: %{z:.2f}<br>' +\n",
    "                     'BBB Permeable: %{marker.color}<extra></extra>'\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='3D Chemical Space Visualization',\n",
    "        scene=dict(\n",
    "            xaxis_title=f'PC1 ({explained_variance[0]:.1%})',\n",
    "            yaxis_title=f'PC2 ({explained_variance[1]:.1%})',\n",
    "            zaxis_title=f'PC3 ({explained_variance[2]:.1%})'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"3D chemical space visualization created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Structure-Activity Relationship Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze molecular fragments and substructures\n",
    "print(\"Analyzing structure-activity relationships...\")\n",
    "\n",
    "# Get molecules with valid SMILES\n",
    "valid_data = data_with_descriptors.dropna(subset=['smiles'])\n",
    "molecules = []\n",
    "permeability = []\n",
    "\n",
    "for idx, row in valid_data.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['smiles'])\n",
    "    if mol is not None:\n",
    "        molecules.append(mol)\n",
    "        permeability.append(row['p_np'])\n",
    "\n",
    "print(f\"Analyzing {len(molecules)} valid molecules\")\n",
    "\n",
    "# Calculate molecular properties for SAR analysis\n",
    "sar_properties = []\n",
    "for i, (mol, perm) in enumerate(zip(molecules, permeability)):\n",
    "    props = {\n",
    "        'index': i,\n",
    "        'permeability': perm,\n",
    "        'mw': Descriptors.MolWt(mol),\n",
    "        'logp': Descriptors.MolLogP(mol),\n",
    "        'tpsa': Descriptors.TPSA(mol),\n",
    "        'hbd': Descriptors.NumHDonors(mol),\n",
    "        'hba': Descriptors.NumHAcceptors(mol),\n",
    "        'rotbonds': Descriptors.NumRotatableBonds(mol),\n",
    "        'aromatic_rings': Descriptors.NumAromaticRings(mol),\n",
    "        'heavy_atoms': Descriptors.HeavyAtomCount(mol)\n",
    "    }\n",
    "    sar_properties.append(props)\n",
    "\n",
    "sar_df = pd.DataFrame(sar_properties)\n",
    "print(f\"Calculated properties for {len(sar_df)} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAR analysis: Property distributions by permeability class\n",
    "key_properties = ['mw', 'logp', 'tpsa', 'hbd', 'hba', 'rotbonds']\n",
    "property_names = ['Molecular Weight', 'LogP', 'TPSA', 'H-Bond Donors', 'H-Bond Acceptors', 'Rotatable Bonds']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (prop, name) in enumerate(zip(key_properties, property_names)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get data for each class\n",
    "    permeable_data = sar_df[sar_df['permeability'] == 1][prop]\n",
    "    non_permeable_data = sar_df[sar_df['permeability'] == 0][prop]\n",
    "    \n",
    "    # Create histograms\n",
    "    ax.hist(non_permeable_data, bins=30, alpha=0.7, label='Non-Permeable', \n",
    "           color='lightcoral', density=True)\n",
    "    ax.hist(permeable_data, bins=30, alpha=0.7, label='Permeable', \n",
    "           color='lightblue', density=True)\n",
    "    \n",
    "    # Add mean lines\n",
    "    ax.axvline(permeable_data.mean(), color='blue', linestyle='--', alpha=0.8, linewidth=2)\n",
    "    ax.axvline(non_permeable_data.mean(), color='red', linestyle='--', alpha=0.8, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{name} Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    from scipy import stats as scipy_stats\n",
    "    t_stat, p_value = scipy_stats.ttest_ind(permeable_data, non_permeable_data)\n",
    "    significance = '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns'\n",
    "    ax.text(0.02, 0.98, f'p-value: {significance}', transform=ax.transAxes, \n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Structure-Activity Relationship Analysis: Molecular Properties vs BBB Permeability', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property correlation analysis\n",
    "print(\"\\nProperty Statistics by BBB Permeability Class:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prop, name in zip(key_properties, property_names):\n",
    "    permeable_data = sar_df[sar_df['permeability'] == 1][prop]\n",
    "    non_permeable_data = sar_df[sar_df['permeability'] == 0][prop]\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Permeable:     mean={permeable_data.mean():.2f}, std={permeable_data.std():.2f}\")\n",
    "    print(f\"  Non-Permeable: mean={non_permeable_data.mean():.2f}, std={non_permeable_data.std():.2f}\")\n",
    "    print(f\"  Difference:    {permeable_data.mean() - non_permeable_data.mean():.2f}\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(permeable_data) - 1) * permeable_data.var() + \n",
    "                         (len(non_permeable_data) - 1) * non_permeable_data.var()) / \n",
    "                        (len(permeable_data) + len(non_permeable_data) - 2))\n",
    "    cohens_d = (permeable_data.mean() - non_permeable_data.mean()) / pooled_std\n",
    "    print(f\"  Effect size:   {cohens_d:.3f} ({'large' if abs(cohens_d) > 0.8 else 'medium' if abs(cohens_d) > 0.5 else 'small'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Molecular Substructure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze functional groups and fragments\n",
    "print(\"Analyzing molecular substructures and functional groups...\")\n",
    "\n",
    "# Define common functional groups and fragments\n",
    "functional_groups = {\n",
    "    'Aromatic_Rings': lambda mol: Descriptors.NumAromaticRings(mol),\n",
    "    'Aliphatic_Rings': lambda mol: Descriptors.NumAliphaticRings(mol),\n",
    "    'Benzene_Rings': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('c1ccccc1'))),\n",
    "    'Hydroxyl_Groups': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[OH]'))),\n",
    "    'Carbonyl_Groups': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#6]=[O]'))),\n",
    "    'Amine_Groups': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[N]'))),\n",
    "    'Ether_Groups': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#6]-[O]-[#6]'))),\n",
    "    'Halogen_Atoms': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[F,Cl,Br,I]'))),\n",
    "    'Carboxylic_Acid': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[CX3](=O)[OX2H1]'))),\n",
    "    'Amide_Groups': lambda mol: len(mol.GetSubstructMatches(Chem.MolFromSmarts('[NX3][CX3](=[OX1])')))\n",
    "}\n",
    "\n",
    "# Calculate functional group counts\n",
    "fragment_data = []\n",
    "for i, (mol, perm) in enumerate(zip(molecules, permeability)):\n",
    "    row = {'index': i, 'permeability': perm}\n",
    "    for fg_name, fg_func in functional_groups.items():\n",
    "        try:\n",
    "            row[fg_name] = fg_func(mol)\n",
    "        except:\n",
    "            row[fg_name] = 0\n",
    "    fragment_data.append(row)\n",
    "\n",
    "fragment_df = pd.DataFrame(fragment_data)\n",
    "print(f\"Calculated functional group counts for {len(fragment_df)} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze functional group distributions\n",
    "print(\"\\nFunctional Group Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fg_analysis = []\n",
    "for fg_name in functional_groups.keys():\n",
    "    permeable_fg = fragment_df[fragment_df['permeability'] == 1][fg_name]\n",
    "    non_permeable_fg = fragment_df[fragment_df['permeability'] == 0][fg_name]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    perm_mean = permeable_fg.mean()\n",
    "    non_perm_mean = non_permeable_fg.mean()\n",
    "    difference = perm_mean - non_perm_mean\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats as scipy_stats\n",
    "    t_stat, p_value = scipy_stats.ttest_ind(permeable_fg, non_permeable_fg)\n",
    "    \n",
    "    fg_analysis.append({\n",
    "        'Functional_Group': fg_name,\n",
    "        'Permeable_Mean': perm_mean,\n",
    "        'Non_Permeable_Mean': non_perm_mean,\n",
    "        'Difference': difference,\n",
    "        'P_Value': p_value,\n",
    "        'Significant': p_value < 0.05\n",
    "    })\n",
    "    \n",
    "    print(f\"{fg_name:20s}: Perm={perm_mean:.2f}, Non-Perm={non_perm_mean:.2f}, \"\n",
    "          f\"Diff={difference:+.2f}, p={p_value:.4f} {'*' if p_value < 0.05 else ''}\")\n",
    "\n",
    "fg_analysis_df = pd.DataFrame(fg_analysis)\n",
    "fg_analysis_df = fg_analysis_df.sort_values('P_Value')\n",
    "\n",
    "print(f\"\\nSignificant functional groups (p < 0.05): {fg_analysis_df['Significant'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Drug Design Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate drug design insights\n",
    "print(\"DRUG DESIGN INSIGHTS FOR BBB PERMEABILITY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Property-based insights\n",
    "print(\"\\n1. MOLECULAR PROPERTY GUIDELINES:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Analyze optimal ranges for BBB-permeable compounds\n",
    "permeable_props = sar_df[sar_df['permeability'] == 1]\n",
    "\n",
    "property_guidelines = {\n",
    "    'Molecular Weight': ('mw', 'Da'),\n",
    "    'LogP (Lipophilicity)': ('logp', ''),\n",
    "    'TPSA (Polar Surface Area)': ('tpsa', 'Ų'),\n",
    "    'Hydrogen Bond Donors': ('hbd', ''),\n",
    "    'Hydrogen Bond Acceptors': ('hba', ''),\n",
    "    'Rotatable Bonds': ('rotbonds', '')\n",
    "}\n",
    "\n",
    "for prop_name, (prop_key, unit) in property_guidelines.items():\n",
    "    data = permeable_props[prop_key]\n",
    "    q25, q75 = data.quantile([0.25, 0.75])\n",
    "    median = data.median()\n",
    "    mean = data.mean()\n",
    "    \n",
    "    print(f\"{prop_name}:\")\n",
    "    print(f\"  Optimal range (IQR): {q25:.1f} - {q75:.1f} {unit}\")\n",
    "    print(f\"  Median: {median:.1f} {unit}, Mean: {mean:.1f} {unit}\")\n",
    "    print()\n",
    "\n",
    "# Feature importance insights\n",
    "if feature_importance_results:\n",
    "    print(\"\\n2. KEY MOLECULAR DESCRIPTORS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Get top features from best model\n",
    "    top_features = feature_importance_results[best_model_name].head(10)\n",
    "    \n",
    "    print(f\"Top 10 predictive features from {best_model_name}:\")\n",
    "    for i, (feature, importance) in enumerate(top_features.items(), 1):\n",
    "        print(f\"{i:2d}. {feature} (importance: {importance:.3f})\")\n",
    "\n",
    "# Functional group insights\n",
    "significant_groups = fg_analysis_df[fg_analysis_df['Significant']]['Functional_Group'].tolist()\n",
    "if significant_groups:\n",
    "    print(\"\\n3. STRUCTURAL FEATURES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(\"Functional groups significantly associated with BBB permeability:\")\n",
    "    for fg in significant_groups[:5]:\n",
    "        fg_data = fg_analysis_df[fg_analysis_df['Functional_Group'] == fg].iloc[0]\n",
    "        direction = \"higher\" if fg_data['Difference'] > 0 else \"lower\"\n",
    "        print(f\"• {fg.replace('_', ' ')}: {direction} counts in permeable compounds\")\n",
    "\n",
    "print(\"\\n4. DESIGN RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Based on the analysis, for BBB-permeable compounds:\")\n",
    "print(\"• Optimize lipophilicity (LogP) within the identified range\")\n",
    "print(\"• Keep polar surface area (TPSA) below the upper threshold\")\n",
    "print(\"• Minimize hydrogen bond donors while maintaining activity\")\n",
    "print(\"• Consider molecular weight constraints for passive diffusion\")\n",
    "print(\"• Incorporate favorable structural features identified in the analysis\")\n",
    "print(\"• Use the trained model for virtual screening of compound libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results and Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "results_dir = '../results/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save SAR analysis\n",
    "sar_path = results_dir + 'sar_analysis.csv'\n",
    "sar_df.to_csv(sar_path, index=False)\n",
    "print(f\"SAR analysis saved to: {sar_path}\")\n",
    "\n",
    "# Save functional group analysis\n",
    "fg_path = results_dir + 'functional_group_analysis.csv'\n",
    "fg_analysis_df.to_csv(fg_path, index=False)\n",
    "print(f\"Functional group analysis saved to: {fg_path}\")\n",
    "\n",
    "# Save chemical space results\n",
    "space_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'PC3': X_pca[:, 2] if X_pca.shape[1] > 2 else 0,\n",
    "    'BBB_Permeability': y\n",
    "})\n",
    "space_path = results_dir + 'chemical_space_pca.csv'\n",
    "space_df.to_csv(space_path, index=False)\n",
    "print(f\"Chemical space analysis saved to: {space_path}\")\n",
    "\n",
    "# Save SHAP results if available\n",
    "if 'shap_values' in locals() and shap_values is not None:\n",
    "    shap_df = pd.DataFrame(shap_values, columns=selected_features)\n",
    "    shap_path = results_dir + 'shap_values.csv'\n",
    "    shap_df.to_csv(shap_path, index=False)\n",
    "    print(f\"SHAP values saved to: {shap_path}\")\n",
    "\n",
    "print(f\"\\nAll interpretability results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Key Findings\n",
    "\n",
    "### Model Interpretability\n",
    "- Feature importance analysis revealed the most predictive molecular descriptors for BBB permeability\n",
    "- SHAP analysis provided individual prediction explanations and feature contributions\n",
    "- The model successfully captures known chemical principles for brain drug delivery\n",
    "\n",
    "### Chemical Space Analysis\n",
    "- PCA visualization shows clear separation between BBB-permeable and non-permeable compounds\n",
    "- The chemical space analysis reveals distinct regions occupied by different permeability classes\n",
    "- Dimensionality reduction captures the key molecular diversity patterns\n",
    "\n",
    "### Structure-Activity Relationships\n",
    "- Significant differences in molecular properties between permeable and non-permeable compounds\n",
    "- Key properties like lipophilicity, molecular weight, and polar surface area show expected trends\n",
    "- Functional group analysis identified structural features associated with BBB permeability\n",
    "\n",
    "### Drug Design Implications\n",
    "- Optimal property ranges have been identified for BBB-permeable compounds\n",
    "- Structural guidelines provide actionable insights for medicinal chemists\n",
    "- The trained model can be used for virtual screening and compound optimization\n",
    "\n",
    "### Applications\n",
    "- Use the model for predicting BBB permeability of new compounds\n",
    "- Apply the property guidelines for compound design and optimization\n",
    "- Leverage the structural insights for scaffold hopping and lead optimization\n",
    "- Utilize the interpretability analysis for understanding model decisions\n",
    "\n",
    "This comprehensive analysis provides both predictive capability and chemical understanding for BBB permeability, enabling data-driven drug design for central nervous system therapeutics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}