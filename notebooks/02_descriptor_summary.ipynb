{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Descriptor Summary and Analysis\n",
    "\n",
    "This notebook focuses on calculating molecular descriptors, analyzing their distributions, and performing correlation analysis to understand the chemical space of BBB permeability.\n",
    "\n",
    "## Objectives:\n",
    "- Calculate comprehensive molecular descriptors\n",
    "- Analyze descriptor distributions for permeable vs non-permeable molecules\n",
    "- Perform correlation analysis between descriptors\n",
    "- Identify key descriptors for BBB permeability\n",
    "- Visualize chemical space and descriptor relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_handler import DataHandler\n",
    "from descriptors import MolecularDescriptors\n",
    "from feature_engineering import FeatureEngineering\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean dataset from previous notebook\n",
    "try:\n",
    "    df = pd.read_csv('../data/BBBP_clean.csv')\n",
    "    print(f\"Clean dataset loaded: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Clean dataset not found. Loading and cleaning original dataset...\")\n",
    "    data_handler = DataHandler()\n",
    "    df = data_handler.load_bbbp_data()\n",
    "    # Basic cleaning\n",
    "    valid_indices = []\n",
    "    for idx, smiles in enumerate(df['smiles']):\n",
    "        is_valid, mol = data_handler.validate_smiles(smiles)\n",
    "        if is_valid:\n",
    "            valid_indices.append(idx)\n",
    "    df = df.iloc[valid_indices].drop_duplicates(subset=['smiles']).reset_index(drop=True)\n",
    "    print(f\"Dataset cleaned: {df.shape}\")\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['p_np'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Molecular Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize descriptor calculator\n",
    "descriptor_calc = MolecularDescriptors()\n",
    "\n",
    "print(\"Calculating molecular descriptors...\")\n",
    "print(\"This may take a few minutes for the full dataset...\")\n",
    "\n",
    "# Calculate descriptors for all molecules\n",
    "descriptors_list = []\n",
    "failed_calculations = []\n",
    "\n",
    "for idx, smiles in enumerate(df['smiles']):\n",
    "    try:\n",
    "        descriptors = descriptor_calc.calculate_all_descriptors(smiles)\n",
    "        descriptors['compound_idx'] = idx\n",
    "        descriptors_list.append(descriptors)\n",
    "    except Exception as e:\n",
    "        failed_calculations.append((idx, smiles, str(e)))\n",
    "        print(f\"Failed to calculate descriptors for compound {idx}: {e}\")\n",
    "\n",
    "# Create descriptors dataframe\n",
    "descriptors_df = pd.DataFrame(descriptors_list)\n",
    "descriptors_df = descriptors_df.set_index('compound_idx')\n",
    "\n",
    "print(f\"\\nDescriptors calculated for {len(descriptors_df)} compounds\")\n",
    "print(f\"Failed calculations: {len(failed_calculations)}\")\n",
    "print(f\"Descriptor features: {descriptors_df.shape[1]}\")\n",
    "\n",
    "# Merge with original data\n",
    "df_with_descriptors = df.join(descriptors_df, how='inner')\n",
    "print(f\"Final dataset shape: {df_with_descriptors.shape}\")\n",
    "\n",
    "# Display descriptor columns\n",
    "descriptor_columns = descriptors_df.columns.tolist()\n",
    "print(f\"\\nCalculated descriptors: {descriptor_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptor Statistics and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptor statistics\n",
    "print(\"=== DESCRIPTOR STATISTICS ===\")\n",
    "descriptor_stats = descriptors_df.describe()\n",
    "print(descriptor_stats)\n",
    "\n",
    "# Check for missing values in descriptors\n",
    "print(\"\\n=== MISSING VALUES IN DESCRIPTORS ===\")\n",
    "missing_values = descriptors_df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found in descriptors\")\n",
    "\n",
    "# Descriptor ranges and distributions\n",
    "print(\"\\n=== DESCRIPTOR RANGES ===\")\n",
    "for col in descriptor_columns:\n",
    "    min_val = descriptors_df[col].min()\n",
    "    max_val = descriptors_df[col].max()\n",
    "    mean_val = descriptors_df[col].mean()\n",
    "    std_val = descriptors_df[col].std()\n",
    "    print(f\"{col:15s}: {min_val:8.3f} - {max_val:8.3f} (mean: {mean_val:6.3f}, std: {std_val:6.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descriptor Distributions by BBB Permeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare descriptor distributions between permeable and non-permeable molecules\n",
    "permeable = df_with_descriptors[df_with_descriptors['p_np'] == 1]\n",
    "non_permeable = df_with_descriptors[df_with_descriptors['p_np'] == 0]\n",
    "\n",
    "print(f\"Permeable molecules: {len(permeable)}\")\n",
    "print(f\"Non-permeable molecules: {len(non_permeable)}\")\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\n=== STATISTICAL COMPARISON (t-test) ===\")\n",
    "statistical_results = []\n",
    "\n",
    "for descriptor in descriptor_columns:\n",
    "    perm_values = permeable[descriptor].dropna()\n",
    "    non_perm_values = non_permeable[descriptor].dropna()\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(perm_values, non_perm_values)\n",
    "    \n",
    "    # Calculate effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(perm_values) - 1) * perm_values.var() + \n",
    "                         (len(non_perm_values) - 1) * non_perm_values.var()) / \n",
    "                        (len(perm_values) + len(non_perm_values) - 2))\n",
    "    cohens_d = (perm_values.mean() - non_perm_values.mean()) / pooled_std\n",
    "    \n",
    "    statistical_results.append({\n",
    "        'descriptor': descriptor,\n",
    "        'permeable_mean': perm_values.mean(),\n",
    "        'non_permeable_mean': non_perm_values.mean(),\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'cohens_d': cohens_d,\n",
    "        'significant': p_value < 0.05\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(statistical_results)\n",
    "stats_df = stats_df.sort_values('p_value')\n",
    "\n",
    "print(\"Top 10 most significant descriptors:\")\n",
    "print(stats_df.head(10)[['descriptor', 'permeable_mean', 'non_permeable_mean', 'p_value', 'cohens_d']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptor Distribution Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for key descriptors\n",
    "key_descriptors = ['LogP', 'MW', 'TPSA', 'HBD', 'HBA', 'RotBonds']\n",
    "available_descriptors = [desc for desc in key_descriptors if desc in descriptor_columns]\n",
    "\n",
    "if len(available_descriptors) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, descriptor in enumerate(available_descriptors[:4]):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot histograms\n",
    "        ax.hist(non_permeable[descriptor].dropna(), alpha=0.6, label='Non-permeable', \n",
    "                bins=30, color='lightcoral', density=True)\n",
    "        ax.hist(permeable[descriptor].dropna(), alpha=0.6, label='Permeable', \n",
    "                bins=30, color='lightblue', density=True)\n",
    "        \n",
    "        ax.set_xlabel(descriptor)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(f'{descriptor} Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Available descriptors for plotting: {available_descriptors}\")\n",
    "    # Plot available descriptors\n",
    "    for descriptor in available_descriptors:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(non_permeable[descriptor].dropna(), alpha=0.6, label='Non-permeable', \n",
    "                bins=30, color='lightcoral', density=True)\n",
    "        plt.hist(permeable[descriptor].dropna(), alpha=0.6, label='Permeable', \n",
    "                bins=30, color='lightblue', density=True)\n",
    "        plt.xlabel(descriptor)\n",
    "        plt.ylabel('Density')\n",
    "        plt.title(f'{descriptor} Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Box Plots for Key Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for comparison\n",
    "if len(available_descriptors) >= 6:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, descriptor in enumerate(available_descriptors[:6]):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Prepare data for box plot\n",
    "        data_to_plot = [non_permeable[descriptor].dropna(), permeable[descriptor].dropna()]\n",
    "        \n",
    "        box_plot = ax.boxplot(data_to_plot, labels=['Non-permeable', 'Permeable'], \n",
    "                             patch_artist=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        box_plot['boxes'][0].set_facecolor('lightcoral')\n",
    "        box_plot['boxes'][1].set_facecolor('lightblue')\n",
    "        \n",
    "        ax.set_ylabel(descriptor)\n",
    "        ax.set_title(f'{descriptor} by BBB Permeability')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    # Create individual box plots\n",
    "    for descriptor in available_descriptors:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        data_to_plot = [non_permeable[descriptor].dropna(), permeable[descriptor].dropna()]\n",
    "        box_plot = plt.boxplot(data_to_plot, labels=['Non-permeable', 'Permeable'], \n",
    "                              patch_artist=True)\n",
    "        box_plot['boxes'][0].set_facecolor('lightcoral')\n",
    "        box_plot['boxes'][1].set_facecolor('lightblue')\n",
    "        plt.ylabel(descriptor)\n",
    "        plt.title(f'{descriptor} by BBB Permeability')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = descriptors_df.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.2f')\n",
    "plt.title('Molecular Descriptor Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated descriptor pairs\n",
    "print(\"\\n=== HIGHLY CORRELATED DESCRIPTOR PAIRS (|r| > 0.7) ===\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'descriptor1': correlation_matrix.columns[i],\n",
    "                'descriptor2': correlation_matrix.columns[j],\n",
    "                'correlation': corr_val\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    high_corr_df = high_corr_df.sort_values('correlation', key=abs, ascending=False)\n",
    "    print(high_corr_df)\n",
    "else:\n",
    "    print(\"No highly correlated pairs found (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation with BBB Permeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between descriptors and BBB permeability\n",
    "permeability_correlations = []\n",
    "\n",
    "for descriptor in descriptor_columns:\n",
    "    corr_coef = df_with_descriptors[descriptor].corr(df_with_descriptors['p_np'])\n",
    "    permeability_correlations.append({\n",
    "        'descriptor': descriptor,\n",
    "        'correlation': corr_coef,\n",
    "        'abs_correlation': abs(corr_coef)\n",
    "    })\n",
    "\n",
    "perm_corr_df = pd.DataFrame(permeability_correlations)\n",
    "perm_corr_df = perm_corr_df.sort_values('abs_correlation', ascending=False)\n",
    "\n",
    "print(\"=== CORRELATION WITH BBB PERMEABILITY ===\")\n",
    "print(perm_corr_df)\n",
    "\n",
    "# Plot correlation with permeability\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red' if x < 0 else 'blue' for x in perm_corr_df['correlation']]\n",
    "bars = plt.barh(range(len(perm_corr_df)), perm_corr_df['correlation'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(perm_corr_df)), perm_corr_df['descriptor'])\n",
    "plt.xlabel('Correlation with BBB Permeability')\n",
    "plt.title('Descriptor Correlation with BBB Permeability')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation values as text\n",
    "for i, (bar, corr) in enumerate(zip(bars, perm_corr_df['correlation'])):\n",
    "    plt.text(corr + (0.01 if corr >= 0 else -0.01), i, f'{corr:.3f}', \n",
    "             ha='left' if corr >= 0 else 'right', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on descriptors\n",
    "feature_eng = FeatureEngineering()\n",
    "\n",
    "# Scale descriptors\n",
    "scaled_descriptors = feature_eng.scale_features(descriptors_df)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(scaled_descriptors)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "print(f\"Number of components: {len(explained_variance_ratio)}\")\n",
    "print(f\"Variance explained by first 5 components: {cumulative_variance[:5]}\")\n",
    "\n",
    "# Plot explained variance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scree plot\n",
    "ax1.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, 'bo-')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('PCA Scree Plot')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance plot\n",
    "ax2.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'ro-')\n",
    "ax2.axhline(y=0.95, color='k', linestyle='--', alpha=0.7, label='95% variance')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find number of components for 95% variance\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"\\nNumber of components needed for 95% variance: {n_components_95}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Chemical Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot chemical space using first two principal components\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create scatter plot colored by permeability\n",
    "permeable_mask = df_with_descriptors['p_np'] == 1\n",
    "non_permeable_mask = df_with_descriptors['p_np'] == 0\n",
    "\n",
    "plt.scatter(pca_result[non_permeable_mask, 0], pca_result[non_permeable_mask, 1], \n",
    "           c='lightcoral', alpha=0.6, label='Non-permeable', s=50)\n",
    "plt.scatter(pca_result[permeable_mask, 0], pca_result[permeable_mask, 1], \n",
    "           c='lightblue', alpha=0.6, label='Permeable', s=50)\n",
    "\n",
    "plt.xlabel(f'PC1 ({explained_variance_ratio[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance_ratio[1]:.1%} variance)')\n",
    "plt.title('Chemical Space Visualization (PCA)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print component loadings for interpretation\n",
    "print(\"\\n=== TOP LOADINGS FOR FIRST TWO PRINCIPAL COMPONENTS ===\")\n",
    "feature_names = descriptors_df.columns\n",
    "\n",
    "# PC1 loadings\n",
    "pc1_loadings = pd.DataFrame({\n",
    "    'descriptor': feature_names,\n",
    "    'loading': pca.components_[0]\n",
    "}).sort_values('loading', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nPC1 (most important loadings):\")\n",
    "print(pc1_loadings.head(5))\n",
    "\n",
    "# PC2 loadings\n",
    "pc2_loadings = pd.DataFrame({\n",
    "    'descriptor': feature_names,\n",
    "    'loading': pca.components_[1]\n",
    "}).sort_values('loading', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nPC2 (most important loadings):\")\n",
    "print(pc2_loadings.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=== MOLECULAR DESCRIPTOR ANALYSIS SUMMARY ===\")\n",
    "print(f\"\\nDataset: {len(df_with_descriptors)} compounds\")\n",
    "print(f\"Descriptors calculated: {len(descriptor_columns)}\")\n",
    "print(f\"Permeable compounds: {len(permeable)} ({len(permeable)/len(df_with_descriptors)*100:.1f}%)\")\n",
    "print(f\"Non-permeable compounds: {len(non_permeable)} ({len(non_permeable)/len(df_with_descriptors)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "\n",
    "# Most discriminative descriptors\n",
    "top_discriminative = stats_df.head(3)\n",
    "print(\"\\nMost discriminative descriptors (lowest p-values):\")\n",
    "for _, row in top_discriminative.iterrows():\n",
    "    direction = \"higher\" if row['permeable_mean'] > row['non_permeable_mean'] else \"lower\"\n",
    "    print(f\"- {row['descriptor']}: Permeable molecules have {direction} values (p={row['p_value']:.2e})\")\n",
    "\n",
    "# Strongest correlations with permeability\n",
    "top_correlations = perm_corr_df.head(3)\n",
    "print(\"\\nStrongest correlations with BBB permeability:\")\n",
    "for _, row in top_correlations.iterrows():\n",
    "    direction = \"positive\" if row['correlation'] > 0 else \"negative\"\n",
    "    print(f\"- {row['descriptor']}: {direction} correlation (r={row['correlation']:.3f})\")\n",
    "\n",
    "# PCA insights\n",
    "print(f\"\\nPCA Analysis:\")\n",
    "print(f\"- First 2 components explain {cumulative_variance[1]:.1%} of variance\")\n",
    "print(f\"- {n_components_95} components needed for 95% variance\")\n",
    "print(f\"- PC1 mainly driven by: {pc1_loadings.iloc[0]['descriptor']} (loading: {pc1_loadings.iloc[0]['loading']:.3f})\")\n",
    "print(f\"- PC2 mainly driven by: {pc2_loadings.iloc[0]['descriptor']} (loading: {pc2_loadings.iloc[0]['loading']:.3f})\")\n",
    "\n",
    "# Highly correlated descriptors\n",
    "if len(high_corr_pairs) > 0:\n",
    "    print(f\"\\nHighly correlated descriptor pairs: {len(high_corr_pairs)}\")\n",
    "    print(\"Consider removing redundant descriptors for model training\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(\"- Focus on top discriminative descriptors for model building\")\n",
    "print(\"- Consider feature selection to remove highly correlated descriptors\")\n",
    "print(\"- Use PCA for dimensionality reduction if needed\")\n",
    "print(\"- Proceed to notebook 03_model_training.ipynb for machine learning\")\n",
    "\n",
    "# Save descriptor data for next notebook\n",
    "df_with_descriptors.to_csv('../data/BBBP_with_descriptors.csv', index=False)\n",
    "print(\"\\nDataset with descriptors saved to '../data/BBBP_with_descriptors.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}