{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Quality Analysis\n",
    "\n",
    "This notebook focuses on loading the BBBP dataset, validating SMILES strings, handling missing values, and performing comprehensive data quality analysis.\n",
    "\n",
    "## Objectives:\n",
    "- Load and explore the BBBP dataset\n",
    "- Validate SMILES strings using RDKit\n",
    "- Identify and handle missing values\n",
    "- Analyze data quality and distribution\n",
    "- Prepare clean dataset for descriptor calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_handler import DataHandler\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load BBBP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data handler\n",
    "data_handler = DataHandler()\n",
    "\n",
    "# Load the BBBP dataset\n",
    "print(\"Loading BBBP dataset...\")\n",
    "df = data_handler.load_bbbp_data()\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== Dataset Information ===\")\n",
    "print(f\"Total number of compounds: {len(df)}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "print(\"\\n=== Data Types ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n=== Basic Statistics ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "class_counts = df['p_np'].value_counts()\n",
    "class_percentages = df['p_np'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=== BBB Permeability Class Distribution ===\")\n",
    "print(f\"Non-permeable (0): {class_counts[0]} ({class_percentages[0]:.1f}%)\")\n",
    "print(f\"Permeable (1): {class_counts[1]} ({class_percentages[1]:.1f}%)\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "class_counts.plot(kind='bar', ax=ax1, color=['lightcoral', 'lightblue'])\n",
    "ax1.set_title('BBB Permeability Class Distribution')\n",
    "ax1.set_xlabel('Permeability Class')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticklabels(['Non-permeable', 'Permeable'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(class_counts.values, labels=['Non-permeable', 'Permeable'], \n",
    "        autopct='%1.1f%%', colors=['lightcoral', 'lightblue'])\n",
    "ax2.set_title('BBB Permeability Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SMILES Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate SMILES strings\n",
    "print(\"Validating SMILES strings...\")\n",
    "\n",
    "valid_smiles = []\n",
    "invalid_smiles = []\n",
    "mol_objects = []\n",
    "\n",
    "for idx, smiles in enumerate(df['smiles']):\n",
    "    is_valid, mol = data_handler.validate_smiles(smiles)\n",
    "    if is_valid:\n",
    "        valid_smiles.append(idx)\n",
    "        mol_objects.append(mol)\n",
    "    else:\n",
    "        invalid_smiles.append(idx)\n",
    "        mol_objects.append(None)\n",
    "\n",
    "# Add molecule objects to dataframe\n",
    "df['mol_object'] = mol_objects\n",
    "\n",
    "print(f\"Valid SMILES: {len(valid_smiles)} ({len(valid_smiles)/len(df)*100:.1f}%)\")\n",
    "print(f\"Invalid SMILES: {len(invalid_smiles)} ({len(invalid_smiles)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if invalid_smiles:\n",
    "    print(\"\\nInvalid SMILES examples:\")\n",
    "    for idx in invalid_smiles[:5]:  # Show first 5 invalid SMILES\n",
    "        print(f\"Index {idx}: {df.loc[idx, 'smiles']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"=== Duplicate Analysis ===\")\n",
    "duplicate_smiles = df['smiles'].duplicated().sum()\n",
    "duplicate_names = df['name'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicate SMILES: {duplicate_smiles}\")\n",
    "print(f\"Duplicate names: {duplicate_names}\")\n",
    "\n",
    "if duplicate_smiles > 0:\n",
    "    print(\"\\nDuplicate SMILES examples:\")\n",
    "    duplicates = df[df['smiles'].duplicated(keep=False)].sort_values('smiles')\n",
    "    print(duplicates[['name', 'smiles', 'p_np']].head(10))\n",
    "\n",
    "# Check SMILES length distribution\n",
    "print(\"\\n=== SMILES Length Analysis ===\")\n",
    "df['smiles_length'] = df['smiles'].str.len()\n",
    "print(f\"SMILES length - Min: {df['smiles_length'].min()}, Max: {df['smiles_length'].max()}, Mean: {df['smiles_length'].mean():.1f}\")\n",
    "\n",
    "# Plot SMILES length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['smiles_length'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('SMILES Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of SMILES String Lengths')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Molecular Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample molecular structures\n",
    "print(\"Sample molecular structures:\")\n",
    "\n",
    "# Get samples from each class\n",
    "permeable_samples = df[df['p_np'] == 1].head(3)\n",
    "non_permeable_samples = df[df['p_np'] == 0].head(3)\n",
    "\n",
    "print(\"\\n=== BBB Permeable Molecules ===\")\n",
    "for idx, row in permeable_samples.iterrows():\n",
    "    if row['mol_object'] is not None:\n",
    "        print(f\"Name: {row['name']}\")\n",
    "        print(f\"SMILES: {row['smiles']}\")\n",
    "        display(Draw.MolToImage(row['mol_object'], size=(300, 300)))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n=== BBB Non-Permeable Molecules ===\")\n",
    "for idx, row in non_permeable_samples.iterrows():\n",
    "    if row['mol_object'] is not None:\n",
    "        print(f\"Name: {row['name']}\")\n",
    "        print(f\"SMILES: {row['smiles']}\")\n",
    "        display(Draw.MolToImage(row['mol_object'], size=(300, 300)))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean dataset\n",
    "print(\"Preparing clean dataset...\")\n",
    "\n",
    "# Remove rows with invalid SMILES\n",
    "clean_df = df[df['mol_object'].notna()].copy()\n",
    "\n",
    "# Remove duplicates based on SMILES (keep first occurrence)\n",
    "initial_count = len(clean_df)\n",
    "clean_df = clean_df.drop_duplicates(subset=['smiles'], keep='first')\n",
    "duplicates_removed = initial_count - len(clean_df)\n",
    "\n",
    "print(f\"Original dataset: {len(df)} compounds\")\n",
    "print(f\"After removing invalid SMILES: {len(df[df['mol_object'].notna()])} compounds\")\n",
    "print(f\"After removing duplicates: {len(clean_df)} compounds\")\n",
    "print(f\"Total compounds removed: {len(df) - len(clean_df)}\")\n",
    "\n",
    "# Final class distribution\n",
    "final_class_counts = clean_df['p_np'].value_counts()\n",
    "final_class_percentages = clean_df['p_np'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\n=== Final Class Distribution ===\")\n",
    "print(f\"Non-permeable (0): {final_class_counts[0]} ({final_class_percentages[0]:.1f}%)\")\n",
    "print(f\"Permeable (1): {final_class_counts[1]} ({final_class_percentages[1]:.1f}%)\")\n",
    "\n",
    "# Save clean dataset\n",
    "clean_df.to_csv('../data/BBBP_clean.csv', index=False)\n",
    "print(\"\\nClean dataset saved to '../data/BBBP_clean.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive data quality report\n",
    "print(\"=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Original dataset size: {len(df)} compounds\")\n",
    "print(f\"Clean dataset size: {len(clean_df)} compounds\")\n",
    "print(f\"Data retention rate: {len(clean_df)/len(df)*100:.1f}%\")\n",
    "print(f\"\\nInvalid SMILES removed: {len(invalid_smiles)}\")\n",
    "print(f\"Duplicate SMILES removed: {duplicates_removed}\")\n",
    "print(f\"\\nFinal class balance:\")\n",
    "print(f\"  - Non-permeable: {final_class_counts[0]} ({final_class_percentages[0]:.1f}%)\")\n",
    "print(f\"  - Permeable: {final_class_counts[1]} ({final_class_percentages[1]:.1f}%)\")\n",
    "print(f\"\\nSMILES length statistics:\")\n",
    "print(f\"  - Min: {clean_df['smiles_length'].min()}\")\n",
    "print(f\"  - Max: {clean_df['smiles_length'].max()}\")\n",
    "print(f\"  - Mean: {clean_df['smiles_length'].mean():.1f}\")\n",
    "print(f\"  - Std: {clean_df['smiles_length'].std():.1f}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "if len(invalid_smiles) > 0:\n",
    "    print(f\"- {len(invalid_smiles)} invalid SMILES were removed from the dataset\")\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"- {duplicates_removed} duplicate compounds were removed\")\n",
    "if abs(final_class_percentages[0] - 50) > 10:\n",
    "    print(f\"- Dataset shows class imbalance ({final_class_percentages[0]:.1f}% vs {final_class_percentages[1]:.1f}%)\")\n",
    "    print(\"  Consider using stratified sampling or class balancing techniques\")\n",
    "print(\"- Dataset is ready for molecular descriptor calculation\")\n",
    "print(\"- Proceed to notebook 02_descriptor_summary.ipynb for descriptor analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}